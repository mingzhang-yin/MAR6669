{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/m.yin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/m.yin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/m.yin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import lda\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# !pip install lda\n",
    "# !pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = '/content/drive/MyDrive/MAR6669-data/select_reviews.json'\n",
    "select_reviews = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = select_reviews['text']\n",
    "txt = list(review_df)\n",
    "rating = list(select_reviews['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I LOVE Mexican food.  Unfortunately, good Mexican food in New Orleans is rather hard to find.  I have tried seemingly ALL the Mexican places in New Orleans proper: Taqueria Corona, Felipe\\'s Taqueria, Juan\\'s Flying Burrito.   In my opinion, none of these are as good as Superior Grill.  \\n\\nMy friends and I went during Happy Hour, which is from 4:30-6:30, seven days a week, when the margaritas are HALF PRICE!  Let me sidestep and talk about the margaritas for a second.  They are amazing.  Far too often, a margarita tastes far too much like pure tequila, and equally far too often, they are simply too weak.  Superior manages to strike the balance perfectly, resulting in an amazing margarita.  \\n\\nI think the food is quite tasty.  I got the crawfish enchiladas, which were quite good.  No, it is not \"authentic\" mexican food, but then again. it tastes good, and by Tex-Mex standards, it is excellent.  Also, they bring you unlimited baskets of chips and salsa for free.  I don\\'t take this for granted, considering Juan\\'s charges you $3 for each basket.',\n",
       " \"It's a hybrid boba/sushi cafe/restaurant/lounge. I went on a Sunday night and it was busy but we were seated right away.\\n\\nWe had the eel avocado onigiri, the shrimp onigiri, the sushi and sashimi platter for 2, and the matcha milkshake. It was more than enough food for 2 and we didn't finish everything. Everything was good for what it was: casual sushi and basic boba. I've never gone to a sushi/boba place so it was nice having both but also weird because it's never served at the same place.\\n\\nIt's not my first choice for boba in the area and it's not my first choice for sushi in the area. I'd come back if I was craving both sushi and boba at the same time but there are a bunch of better boba places and other sushi/Japanese options in the area.\",\n",
       " 'Food was gooood and they have a sauce bar :D v legit. They offer lots of different kinds of hot pot soup bases and lots of different food options. Also great selection of ice cream! They have green tea and red bean which shows its p legit',\n",
       " \"Really lovely salon, small but so welcoming and great customer service. Offered coffee or water. Omar did my Hair and he was so great. He was patient as I explained how I wanted it cut. He was a perfectionist, very kind. It's been years since someone cut my hair with such skill and professionalism. thank you Omar Bree\",\n",
       " \"I have to bump Green Tea up a star after being back a few more times in the past year. I think the sushi has certainly improved - although I still avoid the heavily Americanized/fried rolls. But they do some good versions/variations on tuna rolls and spider rolls, and I like some of the lighter salads and appetizers as well. Took a friend recently who is normally very tough to please with Asian/sushi and she was impressed. So I'm glad this place is still around and perhaps just getting better and better.\",\n",
       " \"I've been going to TCR for about 4 years now! I have never had an issue with them, they are honest, willing to work with you, and very timely with their projects! I appreciate them, and will continue to come to them for my vehicle repair needs! Thank you guys!\",\n",
       " 'Very small area to dine in. Not a lot of space to maneuver and feel comfortable. The food was very good. Wish they served a soup and half sandwich but, overall very good lunch spot.',\n",
       " 'Food is excellent.  This is one of those surprising hole in the wall places.. Counters and stove is immaculate and food is original.',\n",
       " 'So maybe some of you who have seen my reviews before know one of my biggest laments.  That is, I wish we could have great Italian restaurants in my area of Delco.  \\n\\nWhen I say that, I mean the general area south of Baltimore Pike, and east of the Blue Route.  I\\'m fully aware that I could go to Media and land in a far better gastronomical world.  I just wish some of that existed in places like Glenolden, Ridley, Morton, etc.  \\n\\nAt some point I had to get a review of Trieste up here.  I hadn\\'t been here in about 6 or 7 years.  Maybe that\\'s because I never seem to have had anything that was memorable here in my life.  But, I was willing to give them another shot.  After all, I don\\'t remember a time in my life when Trieste didn\\'t exist.  They\\'ve been around since 1960.  At some point, you have to think the \"They must be doing something right\" corollary has to apply, right?\\n\\nRight? \\n\\nWell I\\'m going to do something mildly unique for this review, at least for me.  Trieste is getting the direct comparison treatment from me against another Delco restaurant.  And because they have the new found publicity from being on national tv, and I\\'ve eaten there recently to have something in my memory to compare it to, Trieste is getting the head to head comparison against the new Italian Village (post Robert Irvine makeover).  \\n\\nLet\\'s face it... they\\'re two of the oldest Italian restaurants in our general area.  At some point we must draw the comparison.  \\n\\nSo here we go, course by course...\\n\\nBread... If any of you saw my review of IV, you know that I killed them on serving stale bread.  Trieste served good soft bread on the night I went.  So good, that we ordered a second basket.  Edge - Trieste.  \\n\\nSoup... It\\'s escarole vs escarole, can\\'t get more basic than that.  I\\'d say that flavor-wise it\\'s even.  But, Trieste served me a cup that had at least 8 or 9 little meatballs in it.  I can\\'t remember getting that many at IV.  The meatballs swayed it.  Edge - Trieste.  \\n\\nCaesar salad... the wife had this.  IV upgraded theirs and I am a fan of it.  Trieste\\'s salad, as my wife put it, \"is what it is\".  Edge - Italian Village.  \\n\\nGeneral entree quality...  I\\'ve had good and I\\'ve had not so good at IV, even in the new atmosphere.  Tonight, at Trieste, I ordered a Baked Pasta Anton special.  I\\'d compare to something I might get at a diner.  Which is to say, thoroughly average in quality.  The wife was OK with her sausage scallopini made to order in rosa sauce without mushroom, but she told me it wasn\\'t the best sauce she\\'s had.  So just like every other Italian restaurant in Delco, we will call this even.  \\n\\nGravy quality... had to do this category separately because it is so important.  Maybe you know Italian Village\\'s flavor to their sauce.  Pretty bold, a bit acidic, I know some people who swear by it, and some who can\\'t stand it.  I\\'ve always fallen in the category of generally OK with it.  But, after tasting the sauce Trieste served me tonight, I must say that I have come away with a new found respect... for Italian Village.  Edge - Italian Village\\n\\nPrices... I can\\'t say that I\\'ve combed over the menu and compared it price by price.  Trieste still has that menu that looks like it has over 100 items to it.  But I did pick out a few prices and can compare them to Italian Village\\'s.  Spaghetti and meatballs... IV is $14, Trieste is $12.95.  Chicken parm... IV is $16, Trieste is $13.95.  However... Lasagna is $14 at IV, $14.95 at Trieste.  IV has the occasional dish that comes in lower, especially on the appetizer menu, but Trieste with more dishes in the $12 to $14 range in general just has a less expensive feel to it.  Edge - Trieste.   \\n\\nService... I won\\'t compare this one.  I\\'ve never had a problem with service at IV.  I will just say that I really appreciated the nice service Trieste gave me tonight.  They do have nice ladies doing the serving that seem happy.  There they get kudos.  \\n\\nI did take advantage of the free cannoli via the check in on the Yelp app.  Not bad.  The shell could have used a bit more crisp.  But I\\'d eat another one.  \\n\\nPerhaps you could call Trieste the winner since they won one more category.  But that gravy comparison is a biggie.  Sorry, Trieste, but the sauce that came in the pasta dish tonight just didn\\'t measure up flavor or texture-wise.  Overall, I call it a draw.\\n\\nLike I said before, they must be doing something right.  With that huge menu, I\\'m sure there are some things that are good.  I just am not sure if I want to take the trial and error time in life to find out.',\n",
       " 'I have been consistently disappointed with this practice. They are overbooked and understaffed and do not get back to you with important information. They missed very important details that could have considerably improved the outcome of my last pregnancy and I constantly had to remind them when certain tests were recommended. I think Dr. Morgan means well but is spread too thin and cannot offer an acceptable level of care.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and text represenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "english_stopwords = set(english_stopwords)\n",
    "english_stopwords.update([\"food\", 'one'])\n",
    "txt_clean = []\n",
    "for i in range(len(txt)):    \n",
    "    txt[i] = re.sub(r'\\d+', '', txt[i]) # remove numbers\n",
    "    txt[i] = txt[i].lower()     # lower case\n",
    "    txt[i] = txt[i].translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    txt[i] = txt[i].strip() # remove white space\n",
    "    tokens = word_tokenize(txt[i]) # tokenize\n",
    "    remove_stop = [lemmatizer.lemmatize(i) for i in tokens if not i in english_stopwords] # remove stop words and lemmatize\n",
    "    txt_clean.append(' '.join(remove_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag-of-words representation\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the texts\n",
    "bag_of_words = vectorizer.fit_transform(txt_clean)\n",
    "\n",
    "# Convert to array for easy viewing\n",
    "bag_of_words_array = bag_of_words.toarray()\n",
    "vocab = vectorizer.get_feature_names_out() # array of words \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5278)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_array.shape #  Number of reviews x  Number of unique words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting by MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 500\n",
      "INFO:lda:vocab_size: 5278\n",
      "INFO:lda:n_words: 26341\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 500\n",
      "INFO:lda:<0> log likelihood: -335527\n",
      "INFO:lda:<10> log likelihood: -238615\n",
      "INFO:lda:<20> log likelihood: -233871\n",
      "INFO:lda:<30> log likelihood: -231660\n",
      "INFO:lda:<40> log likelihood: -230113\n",
      "INFO:lda:<50> log likelihood: -228948\n",
      "INFO:lda:<60> log likelihood: -228009\n",
      "INFO:lda:<70> log likelihood: -227197\n",
      "INFO:lda:<80> log likelihood: -227324\n",
      "INFO:lda:<90> log likelihood: -227056\n",
      "INFO:lda:<100> log likelihood: -226489\n",
      "INFO:lda:<110> log likelihood: -226371\n",
      "INFO:lda:<120> log likelihood: -226415\n",
      "INFO:lda:<130> log likelihood: -225605\n",
      "INFO:lda:<140> log likelihood: -225360\n",
      "INFO:lda:<150> log likelihood: -225325\n",
      "INFO:lda:<160> log likelihood: -225291\n",
      "INFO:lda:<170> log likelihood: -225251\n",
      "INFO:lda:<180> log likelihood: -224964\n",
      "INFO:lda:<190> log likelihood: -225149\n",
      "INFO:lda:<200> log likelihood: -224917\n",
      "INFO:lda:<210> log likelihood: -224910\n",
      "INFO:lda:<220> log likelihood: -224918\n",
      "INFO:lda:<230> log likelihood: -224079\n",
      "INFO:lda:<240> log likelihood: -224202\n",
      "INFO:lda:<250> log likelihood: -224191\n",
      "INFO:lda:<260> log likelihood: -224377\n",
      "INFO:lda:<270> log likelihood: -224302\n",
      "INFO:lda:<280> log likelihood: -224573\n",
      "INFO:lda:<290> log likelihood: -224299\n",
      "INFO:lda:<300> log likelihood: -224010\n",
      "INFO:lda:<310> log likelihood: -224446\n",
      "INFO:lda:<320> log likelihood: -224130\n",
      "INFO:lda:<330> log likelihood: -224055\n",
      "INFO:lda:<340> log likelihood: -223846\n",
      "INFO:lda:<350> log likelihood: -223734\n",
      "INFO:lda:<360> log likelihood: -224050\n",
      "INFO:lda:<370> log likelihood: -223938\n",
      "INFO:lda:<380> log likelihood: -224056\n",
      "INFO:lda:<390> log likelihood: -223817\n",
      "INFO:lda:<400> log likelihood: -223427\n",
      "INFO:lda:<410> log likelihood: -223923\n",
      "INFO:lda:<420> log likelihood: -223567\n",
      "INFO:lda:<430> log likelihood: -223577\n",
      "INFO:lda:<440> log likelihood: -223474\n",
      "INFO:lda:<450> log likelihood: -223598\n",
      "INFO:lda:<460> log likelihood: -223495\n",
      "INFO:lda:<470> log likelihood: -223665\n",
      "INFO:lda:<480> log likelihood: -223580\n",
      "INFO:lda:<490> log likelihood: -223675\n",
      "INFO:lda:<499> log likelihood: -223300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x17fa6a590>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = lda.LDA(n_topics=20, n_iter=500, random_state=1)\n",
    "model.fit(bag_of_words_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5278)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # word distribution for each topic\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: service delicious menu everything dish little restaurant amazing\n",
      "Topic 1: bar party place menu great option new friendly\n",
      "Topic 2: job guy company even part high tree spent\n",
      "Topic 3: good breakfast make try nice coffee staff want\n",
      "Topic 4: place didnt dont sure made want would like\n",
      "Topic 5: like get know say menu take italian trieste\n",
      "Topic 6: good great best taco get place love restaurant\n",
      "Topic 7: order time minute phone pick two card le\n",
      "Topic 8: used know away right could visit dr feel\n",
      "Topic 9: good ive really like time first better back\n",
      "Topic 10: store im owner location great day business super\n",
      "Topic 11: year week day friendly office keep experience time\n",
      "Topic 12: time get back service table went order took\n",
      "Topic 13: great hair cut always kid people work patient\n",
      "Topic 14: place pizza back way everything night would wont\n",
      "Topic 15: really got definitely go great special well pretty\n",
      "Topic 16: would told car said customer call manager called\n",
      "Topic 17: room large take thing stay never front much\n",
      "Topic 18: chicken good sauce salad come cheese side meat\n",
      "Topic 19: place best go great ever get wait cant\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0 (top topic: 6)\n",
      "Doc 1 (top topic: 9)\n",
      "Doc 2 (top topic: 18)\n",
      "Doc 3 (top topic: 13)\n",
      "Doc 4 (top topic: 9)\n",
      "Doc 5 (top topic: 11)\n",
      "Doc 6 (top topic: 18)\n",
      "Doc 7 (top topic: 11)\n",
      "Doc 8 (top topic: 5)\n",
      "Doc 9 (top topic: 8)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Doc {} (top topic: {})\".format(i, doc_topic[i].argmax()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
